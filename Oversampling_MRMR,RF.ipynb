{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H7SAUJ5vYsWJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Churn_Modelling.csv')"
      ],
      "metadata": {
        "id": "mAUr8wlMZDW0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "df = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "\n",
        "\n",
        "X = df.drop(columns=['Exited'])\n",
        "y = df['Exited']\n",
        "\n",
        "print(\"Class distribution before oversampling:\", Counter(y))\n",
        "\n",
        "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "print(\"Class distribution after oversampling:\", Counter(y_resampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQdlZVWgZ9hj",
        "outputId": "52565f02-79b0-461e-b0e4-8e5c1531b107"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before oversampling: Counter({0: 7963, 1: 2037})\n",
            "Class distribution after oversampling: Counter({1: 7963, 0: 7963})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymrmr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqOkcgfdas9T",
        "outputId": "f7fe12fc-5897-405f-8a32-9b2fed7a1e8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymrmr\n",
            "  Downloading pymrmr-0.1.11.tar.gz (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/69.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.5/69.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from pymrmr) (1.23.5)\n",
            "Building wheels for collected packages: pymrmr\n",
            "  Building wheel for pymrmr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymrmr: filename=pymrmr-0.1.11-cp310-cp310-linux_x86_64.whl size=389906 sha256=94448d435c849f5bb468317f6adddc8d99aef791170174af292bd6a8a5e20419\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ae/55/4a2479c5f0de7eb363fe970cb18e4a750e03e4e63b1b5c2005\n",
            "Successfully built pymrmr\n",
            "Installing collected packages: pymrmr\n",
            "Successfully installed pymrmr-0.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "df = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "gender_mapping = {'Female': 0, 'Male': 1}\n",
        "df['Gender'] = df['Gender'].map(gender_mapping)\n",
        "\n",
        "selected_features = ['NumOfProducts', 'IsActiveMember', 'Gender', 'Age', 'Balance', 'Tenure']\n",
        "X = df[selected_features]\n",
        "y = df['Exited']\n",
        "print(\"Class distribution before oversampling:\", Counter(y))\n",
        "\n",
        "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "print(\"Class distribution after oversampling:\", Counter(y_resampled))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "report_rf = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "report_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "print(\"Support Vector Machine (SVM) Results:\")\n",
        "print(f\"Accuracy: {accuracy_svm}\")\n",
        "print(\"Classification Report:\\n\", report_svm)\n",
        "\n",
        "\n",
        "# k-Nearest Neighbors (KNN)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "report_knn = classification_report(y_test, y_pred_knn)\n",
        "\n",
        "# Decision Tree (DT)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "report_dt = classification_report(y_test, y_pred_dt)\n",
        "\n",
        "# Print results\n",
        "print(\"Random Forest Results:\")\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(\"Classification Report:\\n\", report_rf)\n",
        "\n",
        "print(\"Support Vector Machine (SVM) Results:\")\n",
        "print(f\"Accuracy: {accuracy_svm}\")\n",
        "print(\"Classification Report:\\n\", report_svm)\n",
        "\n",
        "print(\"k-Nearest Neighbors (KNN) Results:\")\n",
        "print(f\"Accuracy: {accuracy_knn}\")\n",
        "print(\"Classification Report:\\n\", report_knn)\n",
        "\n",
        "print(\"Decision Tree (DT) Results:\")\n",
        "print(f\"Accuracy: {accuracy_dt}\")\n",
        "print(\"Classification Report:\\n\", report_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFu2S8AEb9Oa",
        "outputId": "7362d0a5-5bbe-4d4c-9d20-684563b0041a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before oversampling: Counter({0: 7963, 1: 2037})\n",
            "Class distribution after oversampling: Counter({1: 7963, 0: 7963})\n",
            "Support Vector Machine (SVM) Results:\n",
            "Accuracy: 0.5734463276836158\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.39      0.49      1633\n",
            "           1       0.54      0.76      0.64      1553\n",
            "\n",
            "    accuracy                           0.57      3186\n",
            "   macro avg       0.59      0.58      0.56      3186\n",
            "weighted avg       0.59      0.57      0.56      3186\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.9221594475831764\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92      1633\n",
            "           1       0.88      0.98      0.92      1553\n",
            "\n",
            "    accuracy                           0.92      3186\n",
            "   macro avg       0.93      0.92      0.92      3186\n",
            "weighted avg       0.93      0.92      0.92      3186\n",
            "\n",
            "Support Vector Machine (SVM) Results:\n",
            "Accuracy: 0.5734463276836158\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.39      0.49      1633\n",
            "           1       0.54      0.76      0.64      1553\n",
            "\n",
            "    accuracy                           0.57      3186\n",
            "   macro avg       0.59      0.58      0.56      3186\n",
            "weighted avg       0.59      0.57      0.56      3186\n",
            "\n",
            "k-Nearest Neighbors (KNN) Results:\n",
            "Accuracy: 0.7313245448838669\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.63      0.71      1633\n",
            "           1       0.68      0.84      0.75      1553\n",
            "\n",
            "    accuracy                           0.73      3186\n",
            "   macro avg       0.74      0.73      0.73      3186\n",
            "weighted avg       0.74      0.73      0.73      3186\n",
            "\n",
            "Decision Tree (DT) Results:\n",
            "Accuracy: 0.90646578782172\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.84      0.90      1633\n",
            "           1       0.85      0.97      0.91      1553\n",
            "\n",
            "    accuracy                           0.91      3186\n",
            "   macro avg       0.91      0.91      0.91      3186\n",
            "weighted avg       0.91      0.91      0.91      3186\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skrebate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaORf1rGgBz3",
        "outputId": "1f388db6-516d-4915-b5c3-b8cb876e456f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skrebate\n",
            "  Downloading skrebate-0.62.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from skrebate) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from skrebate) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from skrebate) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skrebate) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skrebate) (3.2.0)\n",
            "Building wheels for collected packages: skrebate\n",
            "  Building wheel for skrebate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skrebate: filename=skrebate-0.62-py3-none-any.whl size=29253 sha256=ab6f6ce2f2b4879924c05a70bf9a57a9db57ed35130691ac27a641d9785ee717\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/67/40/683074a684607162bd0e34dcf7ccdfcab5861c3b2a83286f3a\n",
            "Successfully built skrebate\n",
            "Installing collected packages: skrebate\n",
            "Successfully installed skrebate-0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skfeature-chappers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eq74wIVEW5u",
        "outputId": "fe019efb-2285-4fb1-9ae3-792832cbc425"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skfeature-chappers\n",
            "  Downloading skfeature_chappers-1.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from skfeature-chappers) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from skfeature-chappers) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from skfeature-chappers) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->skfeature-chappers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->skfeature-chappers) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skfeature-chappers) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skfeature-chappers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skfeature-chappers) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->skfeature-chappers) (1.16.0)\n",
            "Installing collected packages: skfeature-chappers\n",
            "Successfully installed skfeature-chappers-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from skfeature.function.similarity_based import reliefF\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "df = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "gender_mapping = {'Female': 0, 'Male': 1}\n",
        "df['Gender'] = df['Gender'].map(gender_mapping)\n",
        "\n",
        "\n",
        "selected_features = ['NumOfProducts', 'IsActiveMember', 'Gender', 'Age', 'Balance', 'Tenure']\n",
        "X = df[selected_features]\n",
        "y = df['Exited']\n",
        "\n",
        "print(\"Class distribution before oversampling:\", Counter(y))\n",
        "\n",
        "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "print(\"Class distribution after oversampling:\", Counter(y_resampled))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "report_rf = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "report_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "# k-Nearest Neighbors (KNN)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "report_knn = classification_report(y_test, y_pred_knn)\n",
        "\n",
        "# Decision Tree (DT)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "report_dt = classification_report(y_test, y_pred_dt)\n",
        "\n",
        "# Feature selection using ReliefF\n",
        "score = reliefF.reliefF(X_resampled.values, y_resampled)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances using ReliefF:\")\n",
        "for feature, importance in zip(selected_features, score):\n",
        "    print(f\"{feature}: {importance}\")\n",
        "\n",
        "# Print results\n",
        "print(\"Random Forest Results:\")\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(\"Classification Report:\\n\", report_rf)\n",
        "\n",
        "print(\"Support Vector Machine (SVM) Results:\")\n",
        "print(f\"Accuracy: {accuracy_svm}\")\n",
        "print(\"Classification Report:\\n\", report_svm)\n",
        "\n",
        "print(\"k-Nearest Neighbors (KNN) Results:\")\n",
        "print(f\"Accuracy: {accuracy_knn}\")\n",
        "print(\"Classification Report:\\n\", report_knn)\n",
        "\n",
        "print(\"Decision Tree (DT) Results:\")\n",
        "print(f\"Accuracy: {accuracy_dt}\")\n",
        "print(\"Classification Report:\\n\", report_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mzBRDyEEoCp",
        "outputId": "676d19a8-59e8-4377-96a7-e6ac2d50601b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before oversampling: Counter({0: 7963, 1: 2037})\n",
            "Class distribution after oversampling: Counter({1: 7963, 0: 7963})\n",
            "Feature Importances using ReliefF:\n",
            "NumOfProducts: 1\n",
            "IsActiveMember: 2\n",
            "Gender: 0\n",
            "Age: 5\n",
            "Balance: 4\n",
            "Tenure: 3\n",
            "Random Forest Results:\n",
            "Accuracy: 0.9221594475831764\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92      1633\n",
            "           1       0.88      0.98      0.92      1553\n",
            "\n",
            "    accuracy                           0.92      3186\n",
            "   macro avg       0.93      0.92      0.92      3186\n",
            "weighted avg       0.93      0.92      0.92      3186\n",
            "\n",
            "Support Vector Machine (SVM) Results:\n",
            "Accuracy: 0.5734463276836158\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.39      0.49      1633\n",
            "           1       0.54      0.76      0.64      1553\n",
            "\n",
            "    accuracy                           0.57      3186\n",
            "   macro avg       0.59      0.58      0.56      3186\n",
            "weighted avg       0.59      0.57      0.56      3186\n",
            "\n",
            "k-Nearest Neighbors (KNN) Results:\n",
            "Accuracy: 0.7313245448838669\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.63      0.71      1633\n",
            "           1       0.68      0.84      0.75      1553\n",
            "\n",
            "    accuracy                           0.73      3186\n",
            "   macro avg       0.74      0.73      0.73      3186\n",
            "weighted avg       0.74      0.73      0.73      3186\n",
            "\n",
            "Decision Tree (DT) Results:\n",
            "Accuracy: 0.90646578782172\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.84      0.90      1633\n",
            "           1       0.85      0.97      0.91      1553\n",
            "\n",
            "    accuracy                           0.91      3186\n",
            "   macro avg       0.91      0.91      0.91      3186\n",
            "weighted avg       0.91      0.91      0.91      3186\n",
            "\n"
          ]
        }
      ]
    }
  ]
}